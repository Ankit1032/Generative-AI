{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f90abe",
   "metadata": {},
   "source": [
    "#### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35eb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState, create_agent\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f966b50",
   "metadata": {},
   "source": [
    "##### Step 1: Define the State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3900c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomState(AgentState):\n",
    "    user_preferences: dict | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc8812",
   "metadata": {},
   "source": [
    "##### Step 2: Middleware that inserts style preference into system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd7e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleMiddleware(AgentMiddleware):\n",
    "    state_schema = CustomState\n",
    "\n",
    "    def before_model(self, state, runtime) -> dict[str, Any] | None:\n",
    "        # handle either a dict or an AgentState-like object\n",
    "        if isinstance(state, dict):\n",
    "            prefs = state.get(\"user_preferences\") or {}\n",
    "        else:\n",
    "            # AgentState or pydantic-like object: use getattr\n",
    "            prefs = getattr(state, \"user_preferences\", {}) or {}\n",
    "\n",
    "        style = prefs.get(\"style\", \"simple\")\n",
    "\n",
    "        # Return a dict that will be merged with the call input (inject system msg)\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": f\"Respond in a {style} style.\"}\n",
    "            ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42109bd",
   "metadata": {},
   "source": [
    "##### Step 3: Use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f28db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    middleware=[StyleMiddleware()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ea978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain transformers\"}],\n",
    "    \"state\": {\"user_preferences\": {\"style\": \"technical\"}}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e4aa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Transformers are a type of model used in machine learning, especially in natural language processing. They help computers understand and generate human language. Here's a simple breakdown:\\n\\n1. **Attention Mechanism**: Transformers use a technique called “attention” to focus on different parts of the input data. This helps them understand the context better, as they can weigh the importance of each word in a sentence.\\n\\n2. **Encoder-Decoder Structure**: Transformers are usually made up of two parts:\\n   - **Encoder**: This part takes the input (like a sentence) and processes it to create a summary or representation.\\n   - **Decoder**: This part takes the summary from the encoder and generates output (like translating that sentence into another language).\\n\\n3. **Parallel Processing**: Unlike previous models that processed data step by step, transformers can process all the words in a sentence at the same time. This makes them faster and more efficient.\\n\\n4. **Applications**: Transformers are used in many applications, such as language translation (like Google Translate), chatbots, and even generating text (like this response).\\n\\nIn summary, transformers are powerful tools that help computers understand and produce human language by using attention and processing data in parallel.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab7d056",
   "metadata": {},
   "source": [
    "#### 2nd Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f28ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c6d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae84e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

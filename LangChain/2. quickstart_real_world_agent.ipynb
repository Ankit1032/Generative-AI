{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c185a2",
   "metadata": {},
   "source": [
    "### Build Real World Agent\n",
    "\n",
    "1. Detailed system prompts for better agent behavior\n",
    "2. Create tools that integrate with external data\n",
    "3. Model configuration for consistent responses\n",
    "4. Structured output for predictable results\n",
    "5. Conversational memory for chat-like interactions\n",
    "6. Create and run the agent create a fully functional agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f02deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\AppData\\Roaming\\Python\\Python314\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ce408d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d808ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Loaded Succesfully!\n"
     ]
    }
   ],
   "source": [
    "# Read API key\n",
    "gpt_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set the environment variable that OpenAI expects\n",
    "if gpt_api_key:\n",
    "    print(\"API Loaded Succesfully!\")\n",
    "else:\n",
    "    raise ValueError(\"GPT_API not found in .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef71924",
   "metadata": {},
   "source": [
    "### 1. Define the system prompt\n",
    "\n",
    "##### The system prompt defines your agentâ€™s role and behavior. Keep it specific and actionable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3a5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa0989",
   "metadata": {},
   "source": [
    "### 2. Create tools\n",
    "\n",
    "##### Tools let a model interact with external systems by calling functions you define. Tools can depend on runtime context and also interact with agent memory.\n",
    "##### Notice below how the get_user_location tool uses runtime context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b270df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4f334",
   "metadata": {},
   "source": [
    "@tool is a decorator that transforms a function into a tool, making it discoverable and callable within a Langchain environment. It allows you to define a function (like get_weather_for_location or get_user_location) and easily integrate it into a Langchain workflow.\n",
    "\n",
    "@dataclass is a decorator that automatically generates methods like __init__, __repr__, etc., for a class. In this case, it simplifies the creation of the Context class, which is used to provide runtime context to tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664550e",
   "metadata": {},
   "source": [
    "### Configure your model\n",
    "\n",
    "##### Set up your language model with the right parameters for your use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b14ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    "    # ... (other params)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1c590",
   "metadata": {},
   "source": [
    "### Define response format\n",
    "\n",
    "##### Optionally, define a structured response format if you need the agent responses to match a specific schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "852c9f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2252d",
   "metadata": {},
   "source": [
    "### Add memory\n",
    "\n",
    "##### Add memory to your agent to maintain state across interactions. This allows the agent to remember previous conversations and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b558db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d27ec",
   "metadata": {},
   "source": [
    "### Create and run the agent\n",
    "\n",
    "##### Now assemble your agent with all the components and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab40bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response=\"Looks like Florida is putting on its best show with sunny weather! It's a bright day to soak up some rays!\", weather_conditions='sunny')\n",
      "ResponseFormat(punny_response=\"You're welcome! I'm always here to brighten your day with some weather puns!\", weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb784f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
